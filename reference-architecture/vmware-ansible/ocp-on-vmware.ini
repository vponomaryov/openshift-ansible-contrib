[vmware]
# unique cluster_id set during script run
cluster_id=

# console port and install type for OpenShift
console_port=8443

# choices are openshift-enterprise or origin
deployment_type=openshift-enterprise

# OpenShift Version. Supported versions are 'v3_6', 'v3_7' and 'v3_9'.
openshift_vers=v3_7

# vCenter host address/username and password
vcenter_host=
vcenter_username=administrator@vsphere.local
vcenter_password=

# name of RHEL template to use for OpenShift install
vcenter_template_name=ocp-server-template-2.0.2

# folder/cluster/resource pool in vCenter to organize VMs
vcenter_datacenter=CNS
vcenter_cluster=
vcenter_resource_pool=ansible_pool
vcenter_datastore=
vcenter_folder=ansible_vms

# It is possible to enable and disable 'yum update' operation and further
# node reboot using 'disable_yum_update_and_reboot' boolean option.
# It can get any Ansible boolean-like value.
disable_yum_update_and_reboot=no

### Docker config ###
# 'docker_registry_url' specifies main docker registry to pull images from.
# Optional. If not set, default one will be used. Example:
# docker_registry_url=myregistry.foo:5000/openshift3/ose-${component}:${version}
docker_registry_url=

# 'docker_additional_registries' option is used to define list of
# additional registries. Optional. Example:
# docker_additional_registries=bar-registry.bar:8888,foo-registry.foo:5000
docker_additional_registries=

# 'docker_insecure_registries' option is used to define list of
# insecure registries. Optional. Example:
# docker_insecure_registries=bar-registry.bar:8888,foo-registry.foo:5000
docker_insecure_registries=

# Specify 'docker_image_tag' to install specific versions of docker images.
# Optional. Example: docker_image_tag=v3.9.3
docker_image_tag=

### Repositories config ###
# Specify 'ose_puddle_repo' option in case it is needed to use downstream
# repository with OpenShift packages, for example development versions.
# It should be link to the packages, not "repo" file with link to the packages.
# If defined, then GA repo will be disabled.
# Example:
# ose_puddle_repo=http://mysite.com/my_openshift_packages/3.9/latest/x86_64/os/
ose_puddle_repo=

# Define 'gluster_puddle_repo' option the same way as 'ose_puddle_repo', just
# for Gluster3 packages. Optional. If defined then GA repo will be disabled.
gluster_puddle_repo=

### CNS docker options ###
# Set following options to change docker image names and their versions
# for CNS pods. Leave empty to make Ansible use default values.
cns_glusterfs_image=rhgs3/rhgs-server-rhel7
cns_glusterfs_version=latest

cns_glusterfs_block_image=rhgs3/rhgs-gluster-block-prov-rhel7
cns_glusterfs_block_version=latest

cns_glusterfs_heketi_image=rhgs3/rhgs-volmanager-rhel7
cns_glusterfs_heketi_version=latest

##########################

# DNS zone where everything will be hosted and app wildcard prefix
dns_zone=
app_dns_prefix=apps

# DNS/gateway/interface name the OpenShift nodes should utilize
vm_dns=
vm_gw=
vm_netmask=
vm_network="VM Network"

# red hat subscription name and password
rhel_subscription_user=
rhel_subscription_pass=

# Internal satellite 6 server
rhel_subscription_server=subscription.rhsm.stage.redhat.com:443
rhsm_katello_url=
rhsm_activation_key=
rhsm_org_id=Default_Organization

# pool with openshift repo access
rhel_subscription_pool=Employee SKU

# bringing your own load balancer?
byo_lb=False
lb_host=haproxy-0

# HA haproxy config
lb_ha_ip=11.11.11.11

# bringing your own NFS server for registry?
byo_nfs=False
nfs_host=nfs-0
nfs_registry_mountpoint=/exports

# create_inventory vars
# number of nodes of each type
master_nodes=1
infra_nodes=0
app_nodes=1
storage_nodes=0

# start node IP address *must be a contiguous space
vm_ipaddr_start=10.20.30.40

# VM IP addresses allocation type. Can be either 'dhcp' or 'static'.
vm_ipaddr_allocation_type=dhcp

# node hostname prefix
ocp_hostname_prefix=

# create_ocp_vars vars
# ldap bind user/password and FQDN ldap domain
# valid auth_types are none, ldap
auth_type=none
ldap_user=openshift
ldap_user_password=FakeLdapLogin
ldap_fqdn=FakeLdapPass

# Deploy OpenShift Web Console
web_console_install=true

# OpenShift SDN (default value redhat/openshift-ovs-subnet)
openshift_sdn=redhat/openshift-ovs-subnet

# Containerized installation of OpenShift using atomic host
containerized=false

# persistent container storage: none, crs, cns
container_storage=none

# Heketi zone list
# If 'heketi_custom_zones' not set or empty then Heketi zones will be
# autocalculated for each of the nodes as unique values.
# If it is required to have specific set of Heketi zones on storage nodes,
# then define 'heketi_custom_zones' var, which is list of zones
# for storage nodes, where each value is zone for just one node.
heketi_custom_zones=98,76,54,32,10

# Disk sizes in Gb of the persistent container storage per CNS/CRS node.
# Examples:
# 'container_storage_disks=100' means we create 1 disk (sdd) of 100 Gb.
# 'container_storage_disks=100,600,200' means we create 3 disks where
# first disk (sdd) is of 100 Gb in size, second (sde) is of 600 Gb and
# third (sdf) is of 200Gb.
container_storage_disks=100,600

# Following is used for deployment of block hosting volume for CNS when
# Block storage is enabled.
container_storage_block_hosting_volume_size=99

# Use 'additional_disks_to_storage_nodes' option to specify storage devices
# that should be attached to the storage nodes, but not used.
additional_disks_to_storage_nodes=100

# persistent container storage disk type. Can be one of following:
# 'thin', 'thick', 'zeroedThick', 'eagerZeroedThick', ... or any other
# type supported by VMWare.
container_storage_disk_type=thin

# Seconds to wait for container storage pods to become ready.
container_storage_glusterfs_timeout=600

# String to use as secret key for performing heketi commands as admin
# If not set then it will be autogenerated.
heketi_admin_key=admin

# String to use as secret key for performing heketi commands as user
# If not set then it will be autogenerated.
heketi_user_key=user

# 'cns_automation_config_file_path' config option refers to the config file of
# the 'cns-automation' repo, which stores automated tests.
# If set, then all the deployment-specific data will be defined there.
# If not set, then no actions will be performed.
# If it is set and playbooks are run not using 'tox' then make sure 'yedit'
# module for ansible is enabled. It can be found using either of followings links:
# - https://github.com/kwoodson/yedit (Author)
# - https://github.com/vponomaryov/yedit (forked)
cns_automation_config_file_path=./cns-automation-config.yaml
